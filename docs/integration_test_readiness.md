# PhantomNet – Integration Test Readiness

**Project:** PhantomNet  
**Phase:** Month 2 – Week 5  
**Purpose:** Confirm system readiness for end-to-end integration testing  
**Status:** READY WITH OBSERVED RISKS

---

## 1. Objective

This document confirms whether PhantomNet is prepared for **integration-level testing**, where multiple components operate together as a single system.

This phase validates:
- Cross-component communication
- Data flow integrity
- Runtime stability under realistic conditions

---

## 2. Components in Scope

The following components are included in integration testing:

### Backend
- FastAPI application
- Background traffic sniffer
- AI threat classification logic
- Firewall service hooks

### Database
- PostgreSQL (`phantomnet_logs`)
- Tables:
  - packet_logs
  - events
  - traffic_stats
  - protocol-specific log tables

### Frontend
- Dashboard
- Events page
- Stats visualization
- API-driven (no mock data)

### Network Simulation
- Mininet 5-node topology
- Switch + host communication
- Honeypot placement within topology

### Honeypots
- SMTP honeypot (initial deployment)
- Event generation into backend pipeline

---

## 3. Deployment Assumptions

- All components can run on **a single development machine**
- PostgreSQL is local or accessible via local network
- Mininet runs with root privileges
- No authentication layer is enabled (Phase 1/2 design)

---

## 4. Integration Test Scope

### What WILL Be Tested
- Backend startup with database connected
- Background sniffer initialization
- SMTP honeypot event generation
- Event persistence in database
- `/api/events` reflecting real DB data
- `/api/stats` aggregating real events
- Frontend rendering backend data
- Mininet traffic reaching honeypots

### What Will NOT Be Tested (This Phase)
- Performance benchmarking
- High-availability or clustering
- Security hardening (auth, RBAC)
- External mail delivery
- Load or stress testing

---

## 5. Preconditions for Testing

All of the following must be true before running tests:

- Backend starts without runtime errors
- Database schema is up to date
- Frontend builds and loads successfully
- Mininet topology launches successfully
- SMTP honeypot process can start
- No mock data is enabled anywhere

---

## 6. Known Risks & Unknowns

### Identified Risks
- Python package management friction in WSL
- Mininet + Python dependency isolation
- SMTP library availability on minimal environments

### Unknowns (To Be Validated During Testing)
- Stability of SMTP honeypot under repeated connections
- Long-running behavior of background sniffer
- Event volume impact on stats aggregation

These unknowns do **not block testing**, but must be observed.

---

## 7. Success Criteria

Integration testing is considered successful if:

- Events generated by honeypots appear in the database
- Backend APIs return consistent, real data
- Frontend reflects backend truth accurately
- No crashes occur during coordinated runtime
- System can be stopped and restarted cleanly

---

## 8. Go / No-Go Decision

**Decision:** ✅ GO

Rationale:
- All core components are operational
- No known blocking defects
- Risks are understood and acceptable
- Testing itself is required to resolve unknowns

---

## 9. Next Actions

- Execute first full integration test run
- Record failures and observations
- Update Week 5 metrics after test completion
- Decide if fixes are needed before Week 6

---

**Prepared By:** PhantomNet Team  
**Date:** Week 5
